{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBFvXsCOxHeV"
   },
   "source": [
    "#  Vision-based End-to-End Driving Tutorial\n",
    "\n",
    "- Website: https://waymo.com/open\n",
    "- GitHub: https://github.com/waymo-research/waymo-open-dataset\n",
    "- Challenge: https://waymo.com/open/challenges/2025/e2e-driving/\n",
    "\n",
    "This tutorial demonstrates how to load, visualize and submit end-to-end driving data. Visit the [Waymo Open Dataset Website](https://waymo.com/open) to download the full dataset.\n",
    "\n",
    "To use, open this notebook in [Colab](https://colab.research.google.com).\n",
    "\n",
    "Uncheck the box \"Reset all runtimes before running\" if you run this colab directly from the remote kernel. Alternatively, you can make a copy before trying to run it by following \"File > Save copy in Drive ...\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dsW0KJtbZ2qZ"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m auth\n\u001b[1;32m      2\u001b[0m auth\u001b[38;5;241m.\u001b[39mauthenticate_user()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import auth\n",
    "auth.authenticate_user()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ga2FjavUaGvN"
   },
   "outputs": [],
   "source": [
    "!gcloud auth login\n",
    "!gcloud auth list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRIvQZ-jeCEs"
   },
   "outputs": [],
   "source": [
    "!gsutil ls gs://waymo_open_dataset_end_to_end_camera_v_1_0_0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pLcb5gjfXc0"
   },
   "outputs": [],
   "source": [
    "!mkdir -p waymo_data/train waymo_data/val waymo_data/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxrRrSWSfZgB"
   },
   "outputs": [],
   "source": [
    "!gsutil -m cp \"gs://waymo_open_dataset_end_to_end_camera_v_1_0_0/training_202504031202_202504151040.tfrecord-*-of-00263\" waymo_data/train/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBYit3Qhxw3E"
   },
   "source": [
    "## Package installation üõ†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "mOGwtE4EyZmY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting waymo-open-dataset-tf-2-12-0==1.6.7\n",
      "  Using cached waymo_open_dataset_tf_2_12_0-1.6.7-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: absl-py==1.4.0 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (1.4.0)\n",
      "Requirement already satisfied: dask==2023.3.1 in /opt/conda/lib/python3.11/site-packages (from dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (2023.3.1)\n",
      "Requirement already satisfied: einsum==0.3.0 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (0.3.0)\n",
      "Requirement already satisfied: google-auth==2.16.2 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (2.16.2)\n",
      "Requirement already satisfied: immutabledict==2.2.0 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (2.2.0)\n",
      "Requirement already satisfied: jax==0.4.13 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (0.4.13)\n",
      "Requirement already satisfied: jaxlib==0.4.13 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (0.4.13)\n",
      "Requirement already satisfied: matplotlib==3.6.1 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (3.6.1)\n",
      "Collecting numpy==1.23.5 (from waymo-open-dataset-tf-2-12-0==1.6.7)\n",
      "  Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: pandas==1.5.3 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (1.5.3)\n",
      "Requirement already satisfied: pillow==9.2.0 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (9.2.0)\n",
      "Requirement already satisfied: plotly==5.13.1 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (5.13.1)\n",
      "Requirement already satisfied: pyarrow==16.0.0 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (16.0.0)\n",
      "Requirement already satisfied: scikit-image==0.20.0 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (0.20.0)\n",
      "Requirement already satisfied: scikit-learn==1.2.2 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (1.2.2)\n",
      "Requirement already satisfied: setuptools==67.6.0 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (67.6.0)\n",
      "Collecting tensorflow==2.13 (from waymo-open-dataset-tf-2-12-0==1.6.7)\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: tensorflow_probability==0.21.0 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (0.21.0)\n",
      "Collecting visu3d==1.5.1 (from waymo-open-dataset-tf-2-12-0==1.6.7)\n",
      "  Using cached visu3d-1.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: dacite==1.8.1 in /opt/conda/lib/python3.11/site-packages (from waymo-open-dataset-tf-2-12-0==1.6.7) (1.8.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from dask==2023.3.1->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from dask==2023.3.1->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (3.0.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from dask==2023.3.1->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from dask==2023.3.1->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (23.2)\n",
      "Requirement already satisfied: partd>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from dask==2023.3.1->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (1.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.11/site-packages (from dask==2023.3.1->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /opt/conda/lib/python3.11/site-packages (from dask==2023.3.1->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (0.12.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from google-auth==2.16.2->waymo-open-dataset-tf-2-12-0==1.6.7) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from google-auth==2.16.2->waymo-open-dataset-tf-2-12-0==1.6.7) (0.3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from google-auth==2.16.2->waymo-open-dataset-tf-2-12-0==1.6.7) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.11/site-packages (from google-auth==2.16.2->waymo-open-dataset-tf-2-12-0==1.6.7) (4.9)\n",
      "Requirement already satisfied: ml_dtypes>=0.1.0 in /opt/conda/lib/python3.11/site-packages (from jax==0.4.13->waymo-open-dataset-tf-2-12-0==1.6.7) (0.2.0)\n",
      "Requirement already satisfied: opt_einsum in /opt/conda/lib/python3.11/site-packages (from jax==0.4.13->waymo-open-dataset-tf-2-12-0==1.6.7) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.11/site-packages (from jax==0.4.13->waymo-open-dataset-tf-2-12-0==1.6.7) (1.11.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-12-0==1.6.7) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-12-0==1.6.7) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-12-0==1.6.7) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-12-0==1.6.7) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-12-0==1.6.7) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib==3.6.1->waymo-open-dataset-tf-2-12-0==1.6.7) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas==1.5.3->waymo-open-dataset-tf-2-12-0==1.6.7) (2023.3.post1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from plotly==5.13.1->waymo-open-dataset-tf-2-12-0==1.6.7) (9.1.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.11/site-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-12-0==1.6.7) (3.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.11/site-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-12-0==1.6.7) (2.31.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.11/site-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-12-0==1.6.7) (2023.9.26)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-12-0==1.6.7) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.11/site-packages (from scikit-image==0.20.0->waymo-open-dataset-tf-2-12-0==1.6.7) (0.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->waymo-open-dataset-tf-2-12-0==1.6.7) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn==1.2.2->waymo-open-dataset-tf-2-12-0==1.6.7) (3.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (1.59.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (3.10.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (16.0.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (4.24.3)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.11/site-packages (from tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (0.34.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from tensorflow_probability==0.21.0->waymo-open-dataset-tf-2-12-0==1.6.7) (5.1.1)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.11/site-packages (from tensorflow_probability==0.21.0->waymo-open-dataset-tf-2-12-0==1.6.7) (0.1.9)\n",
      "Collecting dataclass_array (from visu3d==1.5.1->waymo-open-dataset-tf-2-12-0==1.6.7)\n",
      "  Using cached dataclass_array-1.5.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.11/site-packages (from visu3d==1.5.1->waymo-open-dataset-tf-2-12-0==1.6.7) (0.8.1)\n",
      "Requirement already satisfied: etils[edc,enp,epath,epy,etree] in /opt/conda/lib/python3.11/site-packages (from visu3d==1.5.1->waymo-open-dataset-tf-2-12-0==1.6.7) (1.13.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (0.41.2)\n",
      "Requirement already satisfied: locket in /opt/conda/lib/python3.11/site-packages (from partd>=1.2.0->dask==2023.3.1->dask[dataframe]==2023.3.1->waymo-open-dataset-tf-2-12-0==1.6.7) (1.0.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth==2.16.2->waymo-open-dataset-tf-2-12-0==1.6.7) (0.5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (3.0.0)\n",
      "Requirement already satisfied: lark in /opt/conda/lib/python3.11/site-packages (from dataclass_array->visu3d==1.5.1->waymo-open-dataset-tf-2-12-0==1.6.7) (1.2.2)\n",
      "Requirement already satisfied: attrs>=18.2.0 in /opt/conda/lib/python3.11/site-packages (from dm-tree->tensorflow_probability==0.21.0->waymo-open-dataset-tf-2-12-0==1.6.7) (23.1.0)\n",
      "Requirement already satisfied: importlib_resources in /opt/conda/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]->visu3d==1.5.1->waymo-open-dataset-tf-2-12-0==1.6.7) (6.1.0)\n",
      "Requirement already satisfied: zipp in /opt/conda/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]->visu3d==1.5.1->waymo-open-dataset-tf-2-12-0==1.6.7) (3.17.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (2.1.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from etils[edc,enp,epath,epy,etree]->visu3d==1.5.1->waymo-open-dataset-tf-2-12-0==1.6.7) (4.66.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13->waymo-open-dataset-tf-2-12-0==1.6.7) (3.2.2)\n",
      "Using cached waymo_open_dataset_tf_2_12_0-1.6.7-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.8 MB)\n",
      "Using cached numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Using cached tensorflow-2.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.2 MB)\n",
      "Using cached visu3d-1.5.1-py3-none-any.whl (49 kB)\n",
      "Using cached dataclass_array-1.5.2-py3-none-any.whl (43 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy, tensorflow, dataclass_array, visu3d, waymo-open-dataset-tf-2-12-0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.6\n",
      "    Uninstalling numpy-2.2.6:\n",
      "      Successfully uninstalled numpy-2.2.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.23.5 which is incompatible.\n",
      "seaborn 0.13.0 requires matplotlib!=3.6.1,>=3.3, but you have matplotlib 3.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dataclass_array-1.5.2 numpy-1.23.5 tensorflow-2.13.0 visu3d-1.5.1 waymo-open-dataset-tf-2-12-0-1.6.7\n"
     ]
    }
   ],
   "source": [
    "!pip install waymo-open-dataset-tf-2-12-0==1.6.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Collecting numpy<2.3.0,>=2 (from opencv-python)\n",
      "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m129.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (67.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~ensorflow (/opt/conda/lib/python3.11/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.5\n",
      "    Uninstalling numpy-1.23.5:\n",
      "      Successfully uninstalled numpy-1.23.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.1.1 requires numpy<2.0,>=1.16; python_version <= \"3.11\", but you have numpy 2.2.6 which is incompatible.\n",
      "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 2.2.6 which is incompatible.\n",
      "scipy 1.11.3 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.2.6 which is incompatible.\n",
      "seaborn 0.13.0 requires matplotlib!=3.6.1,>=3.3, but you have matplotlib 3.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 opencv-python-4.12.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vBAbHAxuwmic"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "imported tf\n",
      "importing cv2\n"
     ]
    }
   ],
   "source": [
    "print(\"start\")\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(\"imported tf\")\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "print(\"importing cv2\")\n",
    "import cv2\n",
    "from waymo_open_dataset import dataset_pb2 as open_dataset\n",
    "from waymo_open_dataset.wdl_limited.camera.ops import py_camera_model_ops\n",
    "\n",
    "from waymo_open_dataset.protos import end_to_end_driving_data_pb2 as wod_e2ed_pb2\n",
    "from waymo_open_dataset.protos import end_to_end_driving_submission_pb2 as wod_e2ed_submission_pb2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLqKE2xj-tHH"
   },
   "source": [
    "## Loading the data\n",
    "\n",
    "Visit the [Waymo Open Dataset Website](https://waymo.com/open/) to download the\n",
    "full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9hkOKUd6w8QG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 263 Validation: 93 Test: 266\n"
     ]
    }
   ],
   "source": [
    "# Replace this path with your own tfrecords.\n",
    "# This tutorial is based on using data in the E2E Driving proto format directly,\n",
    "# so choose the correct dataset version.\n",
    "import glob\n",
    "\n",
    "DATASET_FOLDER = \"/home/jovyan/work/data/waymo-e2e/waymo_open_dataset_end_to_end_camera_v_1_0_0\"\n",
    "\n",
    "TRAIN_FILES = glob.glob(os.path.join(DATASET_FOLDER, \"training*.tfrecord*\"))\n",
    "VALIDATION_FILES = glob.glob(os.path.join(DATASET_FOLDER, \"val*.tfrecord*\"))\n",
    "TEST_FILES = glob.glob(os.path.join(DATASET_FOLDER, \"test*.tfrecord*\"))\n",
    "\n",
    "print(\"Train:\", len(TRAIN_FILES), \"Validation:\", len(VALIDATION_FILES), \"Test:\", len(TEST_FILES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgTIikH9Bhv6"
   },
   "source": [
    "Initialize dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mV_m-oc2Bbsn"
   },
   "outputs": [],
   "source": [
    "filenames = tf.io.matching_files(VALIDATION_FILES)\n",
    "dataset = tf.data.TFRecordDataset(filenames, compression_type='')\n",
    "dataset_iter = dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/jovyan/work/data/waymo-e2e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /home/jovyan/work/data/waymo-e2e/waymo_open_dataset_end_to_end_camera_v_1_0_0 | head -20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_iter = iter(dataset)\n",
    "try:\n",
    "    bytes_example = next(dataset_iter)\n",
    "    print(bytes_example)\n",
    "except StopIteration:\n",
    "    print(\"Dataset is empty!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWj7JeomCy1s"
   },
   "source": [
    "Retrieve one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3GIvytJ6BqHi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 809, in __next__\n",
      "    def _type_spec(self):\n",
      "               ^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 772, in _next_internal\n",
      "    return structure.from_compatible_tensor_list(self._element_spec, ret)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 3028, in iterator_get_next\n",
      "    _ops.raise_from_not_ok_status(e, name)\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/framework/ops.py\", line 5888, in raise_from_not_ok_status\n",
      "    if graph and not isinstance(graph, Graph):\n",
      "tensorflow.python.framework.errors_impl.OutOfRangeError: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} End of sequence [Op:IteratorGetNext] name: \n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_13309/3440588892.py\", line 1, in <module>\n",
      "    bytes_example = next(dataset_iter)\n",
      "                    ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4691, in __next__\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 811, in __next__\n",
      "StopIteration\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "bytes_example = next(dataset_iter)\n",
    "data = wod_e2ed_pb2.E2EDFrame()\n",
    "data.ParseFromString(bytes_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaXCcjcVP60q"
   },
   "source": [
    "## Visualizing the future trajectories on image\n",
    "In this tutorial, we will visualize a single camera image and project the trajectory on the three front cameras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLv0k_XlTULt"
   },
   "outputs": [],
   "source": [
    "def return_front3_cameras(data: wod_e2ed_pb2.E2EDFrame):\n",
    "  \"\"\"Return the front_left, front, and front_right cameras as a list of images\"\"\"\n",
    "  image_list = []\n",
    "  calibration_list = []\n",
    "  # CameraName Enum reference:\n",
    "  # https://github.com/waymo-research/waymo-open-dataset/blob/5f8a1cd42491210e7de629b6f8fc09b65e0cbe99/src/waymo_open_dataset/dataset.proto#L50\n",
    "  order = [2, 1, 3]\n",
    "  for camera_name in order:\n",
    "    for index, image_content in enumerate(data.frame.images):\n",
    "      if image_content.name == camera_name:\n",
    "        # Decode the raw image string and convert to numpy type.\n",
    "        calibration = data.frame.context.camera_calibrations[index]\n",
    "        image = tf.io.decode_image(image_content.image).numpy()\n",
    "        image_list.append(image)\n",
    "        calibration_list.append(calibration)\n",
    "        break\n",
    "\n",
    "  return image_list, calibration_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Yfg6ceNTJwq"
   },
   "source": [
    "Visualize the front 3 cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFePW7Y5WZik"
   },
   "outputs": [],
   "source": [
    "front3_camera_image_list, front3_camera_calibration_list = return_front3_cameras(data)\n",
    "concatenated_image = np.concatenate(front3_camera_image_list, axis=1)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(concatenated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UV6sHoX1w2-k"
   },
   "outputs": [],
   "source": [
    "def project_vehicle_to_image(vehicle_pose, calibration, points):\n",
    "  \"\"\"Projects from vehicle coordinate system to image with global shutter.\n",
    "\n",
    "  Arguments:\n",
    "    vehicle_pose: Vehicle pose transform from vehicle into world coordinate\n",
    "      system.\n",
    "    calibration: Camera calibration details (including intrinsics/extrinsics).\n",
    "    points: Points to project of shape [N, 3] in vehicle coordinate system.\n",
    "\n",
    "  Returns:\n",
    "    Array of shape [N, 3], with the latter dimension composed of (u, v, ok).\n",
    "  \"\"\"\n",
    "  # Transform points from vehicle to world coordinate system (can be\n",
    "  # vectorized).\n",
    "  pose_matrix = np.array(vehicle_pose.transform).reshape(4, 4)\n",
    "  world_points = np.zeros_like(points)\n",
    "  for i, point in enumerate(points):\n",
    "    cx, cy, cz, _ = np.matmul(pose_matrix, [*point, 1])\n",
    "    world_points[i] = (cx, cy, cz)\n",
    "\n",
    "  # Populate camera image metadata. Velocity and latency stats are filled with\n",
    "  # zeroes.\n",
    "  extrinsic = tf.reshape(\n",
    "      tf.constant(list(calibration.extrinsic.transform), dtype=tf.float32),\n",
    "      [4, 4])\n",
    "  intrinsic = tf.constant(list(calibration.intrinsic), dtype=tf.float32)\n",
    "  metadata = tf.constant([\n",
    "      calibration.width,\n",
    "      calibration.height,\n",
    "      open_dataset.CameraCalibration.GLOBAL_SHUTTER,\n",
    "  ],\n",
    "                         dtype=tf.int32)\n",
    "  camera_image_metadata = list(vehicle_pose.transform) + [0.0] * 10\n",
    "\n",
    "  # Perform projection and return projected image coordinates (u, v, ok).\n",
    "  return py_camera_model_ops.world_to_image(extrinsic, intrinsic, metadata,\n",
    "                                            camera_image_metadata,\n",
    "                                            world_points).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UAgH_pmoxrJo"
   },
   "outputs": [],
   "source": [
    "def draw_points_on_image(image, points, size):\n",
    "  \"\"\"Draws points on an image.\n",
    "\n",
    "  Args:\n",
    "    image: The image to draw on.\n",
    "    points: A numpy array of shape (N, 2) representing the points to draw.\n",
    "  \"\"\"\n",
    "  for point in points:\n",
    "    cv2.circle(image, (int(point[0]), int(point[1])), size, (255, 0, 0), -1)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nL0uiCL1G4y6"
   },
   "source": [
    "Extract the ego vehicle's future trajectory and reshape to (N, 3) matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Go_GRAlVpQJ6"
   },
   "outputs": [],
   "source": [
    "future_waypoints_matrix = np.stack([data.future_states.pos_x, data.future_states.pos_y, data.future_states.pos_z], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrEuJN4Lm5-7"
   },
   "source": [
    "The pose is always an identity matrix as we already convert world coordinates to vehicle coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kqpRRhoGjbGb"
   },
   "outputs": [],
   "source": [
    "vehicle_pose = data.frame.images[0].pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tucgPv_UoDTp"
   },
   "source": [
    "We convert the ego vehicle's future waypoints to camera space and draw on camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UKzDz0NLezyG"
   },
   "outputs": [],
   "source": [
    "images_with_drawn_points = []\n",
    "for i in range(len(front3_camera_calibration_list)):\n",
    "  waypoints_camera_space = project_vehicle_to_image(vehicle_pose, front3_camera_calibration_list[i], future_waypoints_matrix)\n",
    "  images_with_drawn_points.append(draw_points_on_image(front3_camera_image_list[i], waypoints_camera_space, size=15))\n",
    "concatenated_image = np.concatenate(images_with_drawn_points, axis=1)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(concatenated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUh5UBgM4rv-"
   },
   "source": [
    "## Submission generation\n",
    "\n",
    "The `wod_e2ed_submission_pb2` defines the proto format of the submission.\n",
    "\n",
    "The participants are required to produce **a single trajectory** starting after the last provided frame. The trajectory should follow  `TrajectoryPrediction` format and has a length of 5 seconds and a frequency of 4 HZ. Then the participants should add the corresponding frame name to form `FrameTrajectoryPredictions`.  The evaluation server will compute detailed metrics and add them to the leaderboard.\n",
    "\n",
    "This section will demonstrate how submission file is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1SJS4kc_mot"
   },
   "outputs": [],
   "source": [
    "# Assume we have a predicted stopping trajectory.\n",
    "predicted_trajectory = wod_e2ed_submission_pb2.TrajectoryPrediction(pos_x=np.zeros(20, dtype=np.float32),\n",
    "                                                                    pos_y=np.zeros(20, dtype=np.float32))\n",
    "frame_name = data.frame.context.name\n",
    "frame_trajectory = wod_e2ed_submission_pb2.FrameTrajectoryPredictions(frame_name=frame_name, trajectory=predicted_trajectory)\n",
    "# The final prediction should be a list of FrameTrajectoryPredictions.\n",
    "predictions = [frame_trajectory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtAFtomxBFpg"
   },
   "outputs": [],
   "source": [
    "# Pack for submission.\n",
    "num_submission_shards = 1  # Please modify accordingly.\n",
    "submission_file_base = '/tmp/MySubmission'  # Please modify accordingly.\n",
    "if not os.path.exists(submission_file_base):\n",
    "  os.makedirs(submission_file_base)\n",
    "sub_file_names = [\n",
    "    os.path.join(submission_file_base, part)\n",
    "    for part in [f'part{i}' for i in range(num_submission_shards)]\n",
    "]\n",
    "# As the submission file may be large, we shard them into different chunks.\n",
    "submissions = []\n",
    "num_predictions_per_shard =  math.ceil(len(predictions) / num_submission_shards)\n",
    "for i in range(num_submission_shards):\n",
    "  start = i * num_predictions_per_shard\n",
    "  end = (i + 1) * num_predictions_per_shard\n",
    "  submissions.append(\n",
    "      wod_e2ed_submission_pb2.E2EDChallengeSubmission(\n",
    "          predictions=predictions[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqwJXQhdCcGn"
   },
   "outputs": [],
   "source": [
    "for i, shard in enumerate(submissions):\n",
    "  shard.submission_type  =  wod_e2ed_submission_pb2.E2EDChallengeSubmission.SubmissionType.E2ED_SUBMISSION\n",
    "  shard.authors[:] = ['A', 'B']  # Please modify accordingly.\n",
    "  shard.affiliation = 'Affiliation'  # Please modify accordingly.\n",
    "  shard.account_name = 'acc@domain.com'  # Please modify accordingly.\n",
    "  shard.unique_method_name = 'YourMethodName'  # Please modify accordingly.\n",
    "  shard.method_link = 'method_link'  # Please modify accordingly.\n",
    "  shard.description = ''  # Please modify accordingly.\n",
    "  shard.uses_public_model_pretraining = True # Please modify accordingly.\n",
    "  shard.public_model_names.extend(['Model_name']) # Please modify accordingly.\n",
    "  shard.num_model_parameters = \"200k\" # Please modify accordingly.\n",
    "  with tf.io.gfile.GFile(sub_file_names[i], 'wb') as fp:\n",
    "    fp.write(shard.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TqmlWbYFEPLO"
   },
   "outputs": [],
   "source": [
    "print(submissions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLVzBJxXw33V"
   },
   "source": [
    "## Package submission\n",
    "```\n",
    "cd /tmp\n",
    "tar cvf MySubmission.tar MySubmission\n",
    "gzip MySubmission.tar\n",
    "```\n",
    "Then you can upload `/tmp/MySubmission.tar.gz` to the challenge website.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaQ6UFQaz4fH"
   },
   "source": [
    "## Evaluation\n",
    "Once the predictions are submitted, our eval server will run the [rater feedback metric](https://waymo.com/intl/en_us/open/challenges/2025/e2e-driving/) to compute the rater feedback scores and update the leaderboard. As the rater feedback metric code won't be released, here we provide a simple ADE Metric implementation to help participants self-evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMeLb0pX6s1e"
   },
   "outputs": [],
   "source": [
    "def average_distance_per_step(\n",
    "    predictions , observed_traj, mask\n",
    ") :\n",
    "  \"\"\"Compute L2 distance between proposed trajectories and ground truth.\n",
    "\n",
    "  Args:\n",
    "    predictions: A numpy array representing model predictions of size: [# proposals,\n",
    "      # time steps, spatial features].\n",
    "    observed_traj: A tensor representing the observed trajectory in the logs of\n",
    "      size [# time steps, spatial features]\n",
    "    mask: A boolean tensor representing the time steps that have valid\n",
    "      observations of size [# time steps].\n",
    "\n",
    "  Returns:\n",
    "    A tensor of size [# proposals]\n",
    "  \"\"\"\n",
    "  dist_per_step = np.linalg.norm(\n",
    "      predictions - observed_traj[np.newaxis], axis=-1\n",
    "  )\n",
    "  dist_per_traj = (dist_per_step * mask[np.newaxis]).sum(axis=-1)\n",
    "  valid_steps = np.maximum(mask.sum(axis=-1, keepdims=True), 1.0)\n",
    "  avg_distance = dist_per_traj / valid_steps\n",
    "  return avg_distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeNkBSQI_A8h"
   },
   "source": [
    "Convert both gt and predictions to a format of dictionary for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UyHfj-pz_AU5"
   },
   "outputs": [],
   "source": [
    "# {frame_name: trajectory}\n",
    "gt_dict = {}\n",
    "prediction_dict = {}\n",
    "gt_dict[data.frame.context.name] =  np.stack([data.future_states.pos_x, data.future_states.pos_y], axis=1)\n",
    "for submission in submissions:\n",
    "  for prediction in submission.predictions:\n",
    "    prediction_dict[prediction.frame_name] = np.stack([prediction.trajectory.pos_x, prediction.trajectory.pos_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJhRZ2knDKOe"
   },
   "outputs": [],
   "source": [
    "# Compute ADEs. Our ade calculation is generalized to multiple proposal and masking enabled.\n",
    "ade_list = []\n",
    "for frame_name in gt_dict:\n",
    "  if frame_name not in prediction_dict:\n",
    "    raise ValueError(f'No prediction for {frame_name}')\n",
    "  gt_traj = gt_dict[frame_name]\n",
    "  pred_traj = prediction_dict[frame_name]\n",
    "  mask = np.ones(gt_traj.shape[0], dtype=np.bool_)\n",
    "  ade_list.append(average_distance_per_step(pred_traj[None], gt_traj, mask)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYkS4cgDA0B_"
   },
   "outputs": [],
   "source": [
    "print(f'ADE: {np.mean(ade_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VrGnxGulZLw"
   },
   "outputs": [],
   "source": [
    "# @title The following code shows how to calculate the rater feedback metric.\n",
    "# First, we need to iterate over the dataset to find the frame that contains\n",
    "# the rated trajectory. Usually in a whole run, only one frame contains such label.\n",
    "data_contain_label = None\n",
    "for raw_data in dataset_iter:\n",
    "  data = wod_e2ed_pb2.E2EDFrame()\n",
    "  data.ParseFromString(raw_data)\n",
    "  if len(data.preference_trajectories) > 0 and \\\n",
    "    data.preference_trajectories[0].preference_score != -1:\n",
    "    data_contain_label = data\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cH_MFUZSnqZm"
   },
   "outputs": [],
   "source": [
    "print(data_contain_label.frame.context.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mf_BT47BDw5K"
   },
   "outputs": [],
   "source": [
    "# @title The following code shows how to calculate the rater feedback metric.\n",
    "from waymo_open_dataset.metrics.python import rater_feedback_utils\n",
    "# Assume we have a list of data.\n",
    "data_list = [data_contain_label]\n",
    "rater_specified_trajectories = []\n",
    "rater_scores = []\n",
    "initial_speed = []\n",
    "\n",
    "prediction_trajectories = []\n",
    "prediction_probabilities = []\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "  rater_specified_trajs_and_scores_i = data_list[i].preference_trajectories\n",
    "  current_rater_trajs = []\n",
    "  current_rater_scores = []\n",
    "  for j in range(len(rater_specified_trajs_and_scores_i)):\n",
    "    current_rater_trajs.append(\n",
    "        np.stack(\n",
    "            [\n",
    "                rater_specified_trajs_and_scores_i[j].pos_x,\n",
    "                rater_specified_trajs_and_scores_i[j].pos_y,\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "    )\n",
    "    current_rater_scores.append(rater_specified_trajs_and_scores_i[j].preference_score)\n",
    "  current_rater_scores = np.array(current_rater_scores)\n",
    "\n",
    "  # Initial speed calculation. The last position of past velocity should be\n",
    "  # the current velocity.\n",
    "  vel_x = data.past_states.vel_x[-1]\n",
    "  vel_y = data.past_states.vel_y[-1]\n",
    "  initial_speed.append(np.sqrt(vel_x**2 + vel_y**2))\n",
    "\n",
    "  # Fake prediction.\n",
    "  prediction_traj = np.zeros((20, 2))\n",
    "  # We add an empty axis as the # of proposals is 1\n",
    "  prediction_trajectories.append(prediction_traj[None])\n",
    "  prediction_probabilities.append(np.ones(1))\n",
    "  # Append the current trajectory and score to the batch list.\n",
    "  rater_specified_trajectories.append(current_rater_trajs)\n",
    "  rater_scores.append(current_rater_scores)\n",
    "\n",
    "# Convert the list of numpy array to add batch dimension.\n",
    "initial_speed = np.stack(initial_speed)\n",
    "prediction_trajectories = np.stack(prediction_trajectories)\n",
    "prediction_probabilities = np.stack(prediction_probabilities)\n",
    "\n",
    "rater_feedback_metrics = (\n",
    "        rater_feedback_utils.get_rater_feedback_score(\n",
    "            prediction_trajectories,\n",
    "            prediction_probabilities,\n",
    "            rater_specified_trajectories,\n",
    "            rater_scores,\n",
    "            initial_speed,\n",
    "            frequency=4,  # Default is 4.\n",
    "            length_seconds=5, # Default predict 5 seconds.\n",
    "            output_trust_region_visualization=False,\n",
    "        )\n",
    "    )\n",
    "print(rater_feedback_metrics['rater_feedback_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3q2oFEpqE1y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
